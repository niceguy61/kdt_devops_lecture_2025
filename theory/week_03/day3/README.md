# Week 3 Day 3: ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì™€ ìŠ¤ì¼€ì¤„ë§

<div align="center">

**âš–ï¸ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬** â€¢ **ğŸ“Š QoS í´ë˜ìŠ¤** â€¢ **ğŸ¯ ìŠ¤ì¼€ì¤„ë§**

*Resource Managementë¶€í„° Namespaceê¹Œì§€, íš¨ìœ¨ì ì¸ í´ëŸ¬ìŠ¤í„° ìš´ì˜*

</div>

---

## ğŸ•˜ ì„¸ì…˜ ì •ë³´
**ì‹œê°„**: 09:00-11:50 (ì´ë¡  2.5ì‹œê°„) + 13:00-16:00 (ì‹¤ìŠµ 3ì‹œê°„)
**ëª©í‘œ**: Resource Management + QoS + ìŠ¤ì¼€ì¤„ë§ ì •ì±… + ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê´€ë¦¬
**ë°©ì‹**: í˜‘ì—… ì¤‘ì‹¬ í•™ìŠµ + ë ˆë²¨ë³„ ì°¨ë³„í™”

## ğŸ¯ ì„¸ì…˜ ëª©í‘œ
### ğŸ“š í•™ìŠµ ëª©í‘œ
- **ì´í•´ ëª©í‘œ**: Resource ê´€ë¦¬, QoS í´ë˜ìŠ¤, ìŠ¤ì¼€ì¤„ë§ ì •ì±… ì™„ì „ ì´í•´
- **ì ìš© ëª©í‘œ**: íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ê³¼ ê³ ê°€ìš©ì„± ë°°ì¹˜ ì „ëµ êµ¬í˜„
- **í˜‘ì—… ëª©í‘œ**: íŒ€ë³„ë¡œ ë©€í‹° í…Œë„ŒíŠ¸ í™˜ê²½ êµ¬ì„± ë° ê´€ë¦¬

---

## ğŸ“– Session 1: Resource Requests/Limits + QoS Classes (50ë¶„)

### ğŸ” ê°œë… 1: Resource Requestsì™€ Limits (15ë¶„)
> **ì •ì˜**: Podê°€ ì‚¬ìš©í•  ë¦¬ì†ŒìŠ¤ì˜ ìµœì†Œ ë³´ì¥ëŸ‰ê³¼ ìµœëŒ€ ì œí•œëŸ‰ì„ ì„¤ì •í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜

**Resource ê´€ë¦¬ì˜ í•„ìš”ì„±**:
- **ë¦¬ì†ŒìŠ¤ ê²½í•© ë°©ì§€**: í•œ Podê°€ ëª¨ë“  ë¦¬ì†ŒìŠ¤ë¥¼ ë…ì í•˜ëŠ” ê²ƒ ë°©ì§€
- **ì„±ëŠ¥ ì˜ˆì¸¡**: ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ì˜ ì¼ê´€ì„± ë³´ì¥
- **ë¹„ìš© ìµœì í™”**: ì ì ˆí•œ ë¦¬ì†ŒìŠ¤ í• ë‹¹ìœ¼ë¡œ ë¹„ìš© íš¨ìœ¨ì„± í–¥ìƒ

```mermaid
graph TB
    subgraph "ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ì‹œìŠ¤í…œ"
        subgraph "ë¦¬ì†ŒìŠ¤ ì„¤ì •"
            A[Resource Requests<br/>ìµœì†Œ ë³´ì¥]
            B[Resource Limits<br/>ìµœëŒ€ ì œí•œ]
        end
        
        subgraph "QoS í´ë˜ìŠ¤"
            C[Guaranteed<br/>Requests = Limits]
            D[Burstable<br/>Requests < Limits]
            E[BestEffort<br/>ì„¤ì • ì—†ìŒ]
        end
        
        subgraph "ìŠ¤ì¼€ì¤„ë§"
            F[Node Selection<br/>ë…¸ë“œ ì„ íƒ]
            G[Resource Allocation<br/>ë¦¬ì†ŒìŠ¤ í• ë‹¹]
            H[Eviction Policy<br/>ì¶•ì¶œ ì •ì±…]
        end
    end
    
    A --> C
    A --> D
    B --> C
    B --> D
    C --> F
    D --> F
    E --> F
    F --> G
    G --> H
    
    style A fill:#e8f5e8
    style B fill:#e8f5e8
    style C fill:#fff3e0
    style D fill:#fff3e0
    style E fill:#fff3e0
    style F fill:#ffebee
    style G fill:#ffebee
    style H fill:#ffebee
```

**Resource ì„¤ì • ì˜ˆì‹œ**:
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-demo
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
```

### ğŸ” ê°œë… 2: QoS Classes ì´í•´ (15ë¶„)
> **ì •ì˜**: Podì˜ ë¦¬ì†ŒìŠ¤ ì„¤ì •ì— ë”°ë¼ ìë™ìœ¼ë¡œ í• ë‹¹ë˜ëŠ” ì„œë¹„ìŠ¤ í’ˆì§ˆ í´ë˜ìŠ¤

**QoS í´ë˜ìŠ¤ë³„ íŠ¹ì§•**:

| QoS í´ë˜ìŠ¤ | ì¡°ê±´ | ìš°ì„ ìˆœìœ„ | ì¶•ì¶œ ìˆœì„œ |
|------------|------|----------|-----------|
| **Guaranteed** | Requests = Limits | ìµœê³  | ë§ˆì§€ë§‰ |
| **Burstable** | Requests < Limits | ì¤‘ê°„ | ì¤‘ê°„ |
| **BestEffort** | ì„¤ì • ì—†ìŒ | ìµœì € | ì²« ë²ˆì§¸ |

**QoS í´ë˜ìŠ¤ ì˜ˆì‹œ**:
```yaml
# Guaranteed QoS
resources:
  requests:
    memory: "256Mi"
    cpu: "200m"
  limits:
    memory: "256Mi"
    cpu: "200m"

---
# Burstable QoS
resources:
  requests:
    memory: "128Mi"
    cpu: "100m"
  limits:
    memory: "256Mi"
    cpu: "200m"

---
# BestEffort QoS
# resources ì„¤ì • ì—†ìŒ
```

### ğŸ” ê°œë… 3: ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ê³¼ ìµœì í™” (15ë¶„)
> **ì •ì˜**: ì‹¤ì œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì„¤ì •ì„ ìµœì í™”í•˜ëŠ” ë°©ë²•

**ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ë„êµ¬**:
- **kubectl top**: ê¸°ë³¸ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
- **Metrics Server**: í´ëŸ¬ìŠ¤í„° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- **VPA (Vertical Pod Autoscaler)**: ìë™ ë¦¬ì†ŒìŠ¤ ì¶”ì²œ
- **Prometheus**: ìƒì„¸í•œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„

**ë¦¬ì†ŒìŠ¤ ìµœì í™” ì „ëµ**:
```bash
# 1. í˜„ì¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
kubectl top nodes
kubectl top pods

# 2. Pod ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ìƒì„¸ í™•ì¸
kubectl describe pod <pod-name>

# 3. VPA ì¶”ì²œê°’ í™•ì¸ (VPA ì„¤ì¹˜ í›„)
kubectl get vpa <vpa-name> -o yaml
```

### ğŸ’­ í•¨ê»˜ ìƒê°í•´ë³´ê¸° (5ë¶„)

**ğŸ¤ í˜ì–´ í† ë¡ **:
1. "ì›¹ ì„œë²„ì™€ ë°ì´í„°ë² ì´ìŠ¤ Podì˜ ë¦¬ì†ŒìŠ¤ ì„¤ì •ì´ ë‹¤ë¥¸ ì´ìœ ëŠ”?"
2. "QoS í´ë˜ìŠ¤ê°€ ì‹¤ì œ ìš´ì˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?"

---

## ğŸ“– Session 2: Node Affinity + Pod Anti-Affinity ìŠ¤ì¼€ì¤„ë§ (50ë¶„)

### ğŸ” ê°œë… 1: Node Affinity ê¸°ë³¸ ê°œë… (15ë¶„)
> **ì •ì˜**: Podë¥¼ íŠ¹ì • ë…¸ë“œì— ë°°ì¹˜í•˜ê±°ë‚˜ ë°°ì¹˜í•˜ì§€ ì•Šë„ë¡ ì œì–´í•˜ëŠ” ìŠ¤ì¼€ì¤„ë§ ê·œì¹™

**Node Affinity íƒ€ì…**:
- **requiredDuringSchedulingIgnoredDuringExecution**: í•„ìˆ˜ ì¡°ê±´ (Hard)
- **preferredDuringSchedulingIgnoredDuringExecution**: ì„ í˜¸ ì¡°ê±´ (Soft)

**Node Affinity ì‚¬ìš© ì‚¬ë¡€**:
- **í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­**: GPUê°€ ìˆëŠ” ë…¸ë“œì—ë§Œ ML ì›Œí¬ë¡œë“œ ë°°ì¹˜
- **ì§€ì—­ ë¶„ì‚°**: ë‹¤ë¥¸ ê°€ìš© ì˜ì—­ì˜ ë…¸ë“œì— Pod ë¶„ì‚°
- **ì„±ëŠ¥ ìµœì í™”**: SSDê°€ ìˆëŠ” ë…¸ë“œì— ë°ì´í„°ë² ì´ìŠ¤ ë°°ì¹˜

```yaml
# Node Affinity ì˜ˆì‹œ
apiVersion: v1
kind: Pod
metadata:
  name: node-affinity-demo
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/arch
            operator: In
            values:
            - amd64
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: node-type
            operator: In
            values:
            - ssd
  containers:
  - name: app
    image: nginx
```

### ğŸ” ê°œë… 2: Pod Anti-Affinity ê³ ê°€ìš©ì„± (15ë¶„)
> **ì •ì˜**: Pod ê°„ì˜ ë°°ì¹˜ ê´€ê³„ë¥¼ ì œì–´í•˜ì—¬ ê³ ê°€ìš©ì„±ê³¼ ì„±ëŠ¥ì„ ë³´ì¥í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜

**Pod Anti-Affinity ì „ëµ**:
- **ê³ ê°€ìš©ì„±**: ê°™ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ Podë¥¼ ë‹¤ë¥¸ ë…¸ë“œì— ë¶„ì‚°
- **ì„±ëŠ¥ ê²©ë¦¬**: ë¦¬ì†ŒìŠ¤ ì§‘ì•½ì ì¸ Podë“¤ì„ ë¶„ë¦¬
- **ì¥ì•  ë„ë©”ì¸ ë¶„ì‚°**: ë‹¤ë¥¸ ê°€ìš© ì˜ì—­ì— Pod ë°°ì¹˜

```yaml
# Pod Anti-Affinity ì˜ˆì‹œ
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - web-app
            topologyKey: kubernetes.io/hostname
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - web-app
              topologyKey: topology.kubernetes.io/zone
      containers:
      - name: web
        image: nginx
```

### ğŸ” ê°œë… 3: Taintsì™€ Tolerations (15ë¶„)
> **ì •ì˜**: ë…¸ë“œì— ì œì•½ì„ ì„¤ì •í•˜ê³  íŠ¹ì • Podë§Œ í•´ë‹¹ ë…¸ë“œì— ìŠ¤ì¼€ì¤„ë§ë˜ë„ë¡ í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜

**Taintsì™€ Tolerations ì‚¬ìš©ë²•**:
```bash
# 1. ë…¸ë“œì— Taint ì„¤ì •
kubectl taint nodes node1 key1=value1:NoSchedule

# 2. Taint í™•ì¸
kubectl describe node node1

# 3. Taint ì œê±°
kubectl taint nodes node1 key1=value1:NoSchedule-
```

**Toleration ì„¤ì •**:
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: toleration-demo
spec:
  tolerations:
  - key: "key1"
    operator: "Equal"
    value: "value1"
    effect: "NoSchedule"
  containers:
  - name: app
    image: nginx
```

### ğŸ’­ í•¨ê»˜ ìƒê°í•´ë³´ê¸° (5ë¶„)

**ğŸ¤ í˜ì–´ í† ë¡ **:
1. "ë°ì´í„°ë² ì´ìŠ¤ í´ëŸ¬ìŠ¤í„°ì—ì„œ Anti-Affinityê°€ ì¤‘ìš”í•œ ì´ìœ ëŠ”?"
2. "Taintsì™€ Node Affinityì˜ ì°¨ì´ì ê³¼ ì‚¬ìš© ì‹œê¸°ëŠ”?"

---

## ğŸ“– Session 3: Namespace ë©€í‹° í…Œë„Œì‹œ + ResourceQuota (50ë¶„)

### ğŸ” ê°œë… 1: Namespace ê¸°ë³¸ ê°œë… (15ë¶„)
> **ì •ì˜**: í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ë¦¬ì†ŒìŠ¤ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” ê°€ìƒ í´ëŸ¬ìŠ¤í„°

**Namespace ì‚¬ìš© ëª©ì **:
- **í™˜ê²½ ë¶„ë¦¬**: dev, staging, production í™˜ê²½ ë¶„ë¦¬
- **íŒ€ ë¶„ë¦¬**: ì—¬ëŸ¬ íŒ€ì´ ê°™ì€ í´ëŸ¬ìŠ¤í„° ê³µìœ 
- **ë¦¬ì†ŒìŠ¤ ê²©ë¦¬**: ë„¤íŠ¸ì›Œí¬, ìŠ¤í† ë¦¬ì§€, ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ê²©ë¦¬
- **ê¶Œí•œ ê´€ë¦¬**: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ ì ‘ê·¼ ê¶Œí•œ ì œì–´

```bash
# Namespace ìƒì„±
kubectl create namespace development
kubectl create namespace staging
kubectl create namespace production

# Namespace í™•ì¸
kubectl get namespaces

# íŠ¹ì • Namespaceì˜ ë¦¬ì†ŒìŠ¤ í™•ì¸
kubectl get pods -n development
```

### ğŸ” ê°œë… 2: ResourceQuota ë¦¬ì†ŒìŠ¤ ì œí•œ (15ë¶„)
> **ì •ì˜**: Namespaceë³„ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¦¬ì†ŒìŠ¤ì˜ ì´ëŸ‰ì„ ì œí•œí•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜

**ResourceQuota ì„¤ì • í•­ëª©**:
- **ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤**: CPU, ë©”ëª¨ë¦¬ ì´ ì‚¬ìš©ëŸ‰
- **ìŠ¤í† ë¦¬ì§€ ë¦¬ì†ŒìŠ¤**: PVC ê°œìˆ˜, ìŠ¤í† ë¦¬ì§€ ì´ ìš©ëŸ‰
- **ì˜¤ë¸Œì íŠ¸ ê°œìˆ˜**: Pod, Service, Secret ë“±ì˜ ê°œìˆ˜

```yaml
# ResourceQuota ì˜ˆì‹œ
apiVersion: v1
kind: ResourceQuota
metadata:
  name: dev-quota
  namespace: development
spec:
  hard:
    # ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤
    requests.cpu: "4"
    requests.memory: 8Gi
    limits.cpu: "8"
    limits.memory: 16Gi
    
    # ì˜¤ë¸Œì íŠ¸ ê°œìˆ˜
    pods: "10"
    services: "5"
    secrets: "10"
    persistentvolumeclaims: "4"
    
    # ìŠ¤í† ë¦¬ì§€
    requests.storage: 100Gi
```

### ğŸ” ê°œë… 3: LimitRangeì™€ ë„¤íŠ¸ì›Œí¬ ì •ì±… (15ë¶„)
> **ì •ì˜**: ê°œë³„ ë¦¬ì†ŒìŠ¤ì˜ ê¸°ë³¸ê°’ê³¼ ì œí•œê°’ì„ ì„¤ì •í•˜ê³  ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ì„ ì œì–´

**LimitRange ì„¤ì •**:
```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: dev-limits
  namespace: development
spec:
  limits:
  - default:
      cpu: "200m"
      memory: "256Mi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
    max:
      cpu: "1"
      memory: "1Gi"
    min:
      cpu: "50m"
      memory: "64Mi"
    type: Container
```

**NetworkPolicy ê¸°ë³¸ ì˜ˆì‹œ**:
```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
  namespace: development
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-web-traffic
  namespace: development
spec:
  podSelector:
    matchLabels:
      app: web
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: production
    ports:
    - protocol: TCP
      port: 80
```

### ğŸ’­ í•¨ê»˜ ìƒê°í•´ë³´ê¸° (5ë¶„)

**ğŸ¤ í˜ì–´ í† ë¡ **:
1. "ë©€í‹° í…Œë„ŒíŠ¸ í™˜ê²½ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê²©ë¦¬ ìš”ì†ŒëŠ”?"
2. "ResourceQuotaì™€ LimitRangeì˜ ì°¨ì´ì ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ”?"

---

## ğŸ› ï¸ ì‹¤ìŠµ ì±Œë¦°ì§€ (3ì‹œê°„)

### ğŸ¯ ì‹¤ìŠµ ê°œìš”
**ëª©í‘œ**: ë©€í‹° í…Œë„ŒíŠ¸ í™˜ê²½ êµ¬ì„± ë° ë¦¬ì†ŒìŠ¤ ìµœì í™”

### ğŸš€ Phase 1: Resource ì„¤ì •ê³¼ QoS ìµœì í™” (90ë¶„)

#### Step 1: ë‹¤ì–‘í•œ QoS í´ë˜ìŠ¤ Pod ìƒì„± (30ë¶„)
```yaml
# guaranteed-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: guaranteed-pod
  labels:
    qos: guaranteed
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        memory: "256Mi"
        cpu: "200m"
      limits:
        memory: "256Mi"
        cpu: "200m"

---
# burstable-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: burstable-pod
  labels:
    qos: burstable
spec:
  containers:
  - name: app
    image: nginx
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "400m"

---
# besteffort-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: besteffort-pod
  labels:
    qos: besteffort
spec:
  containers:
  - name: app
    image: nginx
    # resources ì„¤ì • ì—†ìŒ
```

#### Step 2: ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ (30ë¶„)
```bash
# 1. Pod ë°°í¬
kubectl apply -f guaranteed-pod.yaml
kubectl apply -f burstable-pod.yaml
kubectl apply -f besteffort-pod.yaml

# 2. QoS í´ë˜ìŠ¤ í™•ì¸
kubectl get pods -o custom-columns=NAME:.metadata.name,QOS:.status.qosClass

# 3. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
kubectl top pods
kubectl describe pod guaranteed-pod
kubectl describe pod burstable-pod
kubectl describe pod besteffort-pod

# 4. ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ (ë¶€í•˜ ìƒì„±)
kubectl exec -it burstable-pod -- sh -c "yes > /dev/null &"
kubectl top pods
```

#### Step 3: VPAë¥¼ í†µí•œ ë¦¬ì†ŒìŠ¤ ìµœì í™” (30ë¶„)
```yaml
# vpa-demo.yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: web-app-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: web-app
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: web
      maxAllowed:
        cpu: 1
        memory: 500Mi
      minAllowed:
        cpu: 100m
        memory: 50Mi

---
# í…ŒìŠ¤íŠ¸ìš© Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
    spec:
      containers:
      - name: web
        image: nginx
        resources:
          requests:
            cpu: 50m
            memory: 32Mi
```

### ğŸŒŸ Phase 2: ê³ ê°€ìš©ì„± ìŠ¤ì¼€ì¤„ë§ êµ¬ì„± (90ë¶„)

#### Step 1: Node Labelingê³¼ Affinity ì„¤ì • (30ë¶„)
```bash
# 1. ë…¸ë“œì— ë ˆì´ë¸” ì¶”ê°€
kubectl label nodes <node1> node-type=compute
kubectl label nodes <node2> node-type=storage
kubectl label nodes <node3> zone=us-west-2a
kubectl label nodes <node4> zone=us-west-2b

# 2. ë ˆì´ë¸” í™•ì¸
kubectl get nodes --show-labels
```

```yaml
# node-affinity-demo.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: compute-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: compute-app
  template:
    metadata:
      labels:
        app: compute-app
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-type
                operator: In
                values:
                - compute
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: zone
                operator: In
                values:
                - us-west-2a
      containers:
      - name: app
        image: nginx
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
```

#### Step 2: Pod Anti-Affinity ê³ ê°€ìš©ì„± êµ¬ì„± (30ë¶„)
```yaml
# ha-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ha-web-app
spec:
  replicas: 4
  selector:
    matchLabels:
      app: ha-web-app
  template:
    metadata:
      labels:
        app: ha-web-app
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - ha-web-app
            topologyKey: kubernetes.io/hostname
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - ha-web-app
              topologyKey: topology.kubernetes.io/zone
      containers:
      - name: web
        image: nginx
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
```

#### Step 3: Taintsì™€ Tolerations í…ŒìŠ¤íŠ¸ (30ë¶„)
```bash
# 1. ë…¸ë“œì— Taint ì„¤ì •
kubectl taint nodes <node-name> dedicated=database:NoSchedule

# 2. Tolerationì´ ì—†ëŠ” Pod ë°°í¬ ì‹œë„
kubectl run test-pod --image=nginx

# 3. Pod ìƒíƒœ í™•ì¸ (Pending ìƒíƒœ)
kubectl get pods
kubectl describe pod test-pod

# 4. Tolerationì´ ìˆëŠ” Pod ë°°í¬
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: tolerated-pod
spec:
  tolerations:
  - key: "dedicated"
    operator: "Equal"
    value: "database"
    effect: "NoSchedule"
  containers:
  - name: app
    image: nginx
EOF

# 5. Taint ì œê±°
kubectl taint nodes <node-name> dedicated=database:NoSchedule-
```

### ğŸ† Phase 3: ë©€í‹° í…Œë„ŒíŠ¸ í™˜ê²½ êµ¬ì„± (30ë¶„)

#### Namespaceë³„ í™˜ê²½ êµ¬ì„±
```bash
# 1. ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
kubectl create namespace team-a
kubectl create namespace team-b
kubectl create namespace shared

# 2. ResourceQuota ì ìš©
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ResourceQuota
metadata:
  name: team-a-quota
  namespace: team-a
spec:
  hard:
    requests.cpu: "2"
    requests.memory: 4Gi
    limits.cpu: "4"
    limits.memory: 8Gi
    pods: "10"
    services: "5"

---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: team-b-quota
  namespace: team-b
spec:
  hard:
    requests.cpu: "1"
    requests.memory: 2Gi
    limits.cpu: "2"
    limits.memory: 4Gi
    pods: "5"
    services: "3"
EOF

# 3. LimitRange ì ìš©
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: LimitRange
metadata:
  name: team-a-limits
  namespace: team-a
spec:
  limits:
  - default:
      cpu: "200m"
      memory: "256Mi"
    defaultRequest:
      cpu: "100m"
      memory: "128Mi"
    type: Container
EOF

# 4. ê° ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬
kubectl create deployment web-app --image=nginx -n team-a
kubectl create deployment api-app --image=nginx -n team-b

# 5. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
kubectl describe quota -n team-a
kubectl describe quota -n team-b
kubectl get limitrange -n team-a
```

---

## ğŸ“ ì¼ì¼ ë§ˆë¬´ë¦¬

### âœ… ì˜¤ëŠ˜ì˜ ì„±ê³¼
- [ ] Resource Requests/Limitsì™€ QoS í´ë˜ìŠ¤ ì´í•´ ì™„ë£Œ
- [ ] Node Affinityì™€ Pod Anti-Affinityë¡œ ê³ ê°€ìš©ì„± êµ¬ì„±
- [ ] Namespace ê¸°ë°˜ ë©€í‹° í…Œë„ŒíŠ¸ í™˜ê²½ êµ¬ì¶•
- [ ] ResourceQuotaì™€ LimitRangeë¡œ ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì •
- [ ] ì‹¤ì œ ì›Œí¬ë¡œë“œ ìŠ¤ì¼€ì¤„ë§ ìµœì í™” ê²½í—˜

### ğŸ¯ ë‚´ì¼ ì¤€ë¹„ì‚¬í•­
- **ì˜ˆìŠµ**: RBACê³¼ ServiceAccountì˜ ê°œë…
- **ë³µìŠµ**: kubectlì„ ì´ìš©í•œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ ëª…ë ¹ì–´
- **í™˜ê²½**: ì˜¤ëŠ˜ ìƒì„±í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì™€ ë¦¬ì†ŒìŠ¤ ì •ë¦¬

---

<div align="center">

**ğŸ‰ Day 3 ì™„ë£Œ!** 

*íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì™€ ìŠ¤ì¼€ì¤„ë§ ì „ëµì„ ì™„ì „íˆ ë§ˆìŠ¤í„°í–ˆìŠµë‹ˆë‹¤*

</div>