# Week 2 Day 3 Session 3: ëª¨ë‹ˆí„°ë§ & ê´€ì¸¡ì„±

<div align="center">
**ğŸ“Š ëª¨ë‹ˆí„°ë§** â€¢ **ğŸ” ê´€ì¸¡ì„±**
*ì»¨í…Œì´ë„ˆ í™˜ê²½ì—ì„œì˜ í¬ê´„ì ì¸ ê´€ì¸¡ì„± êµ¬ì¶• ë°©ë²• ì´í•´*
</div>

---

## ğŸ•˜ ì„¸ì…˜ ì •ë³´
**ì‹œê°„**: 11:00-11:50 (50ë¶„)
**ëª©í‘œ**: ì»¨í…Œì´ë„ˆ í™˜ê²½ì—ì„œì˜ í¬ê´„ì ì¸ ê´€ì¸¡ì„± êµ¬ì¶• ë°©ë²• ì´í•´
**ë°©ì‹**: ì´ë¡  ê°•ì˜ + í˜ì–´ í† ë¡ 

## ğŸ¯ ì„¸ì…˜ ëª©í‘œ
### ğŸ“š í•™ìŠµ ëª©í‘œ
- **ì´í•´ ëª©í‘œ**: ì»¨í…Œì´ë„ˆ í™˜ê²½ì—ì„œì˜ í¬ê´„ì ì¸ ê´€ì¸¡ì„± êµ¬ì¶• ë°©ë²• ì´í•´
- **ì ìš© ëª©í‘œ**: ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶• ëŠ¥ë ¥ ìŠµë“
- **í˜‘ì—… ëª©í‘œ**: ê°œë³„ í•™ìŠµ í›„ ê²½í—˜ ê³µìœ  ë° ì§ˆì˜ì‘ë‹µ

## ğŸ“– í•µì‹¬ ê°œë… (35ë¶„)

### ğŸ” ê°œë… 1: ê´€ì¸¡ì„±ì˜ 3ìš”ì†Œ (12ë¶„)
> **ì •ì˜**: ì‹œìŠ¤í…œì˜ ë‚´ë¶€ ìƒíƒœë¥¼ ì™¸ë¶€ì—ì„œ ê´€ì°°í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ë©”íŠ¸ë¦­, ë¡œê·¸, ì¶”ì ì˜ í†µí•©

**ê´€ì¸¡ì„± ì•„í‚¤í…ì²˜**:
```mermaid
graph TB
    subgraph "ê´€ì¸¡ì„± 3ìš”ì†Œ"
        A[ë©”íŠ¸ë¦­<br/>Metrics<br/>ì‹œê³„ì—´ ë°ì´í„°] --> D[ì™„ì „í•œ ê´€ì¸¡ì„±]
        B[ë¡œê·¸<br/>Logs<br/>ì´ë²¤íŠ¸ ê¸°ë¡] --> D
        C[ì¶”ì <br/>Traces<br/>ìš”ì²­ íë¦„] --> D
    end
    
    subgraph "ìˆ˜ì§‘ ë„êµ¬"
        E[Prometheus<br/>ë©”íŠ¸ë¦­ ìˆ˜ì§‘] --> A
        F[Fluentd<br/>ë¡œê·¸ ìˆ˜ì§‘] --> B
        G[Jaeger<br/>ë¶„ì‚° ì¶”ì ] --> C
    end
    
    subgraph "ë¶„ì„ ë„êµ¬"
        H[Grafana<br/>ì‹œê°í™”] --> D
        I[Elasticsearch<br/>ë¡œê·¸ ë¶„ì„] --> D
        J[Kibana<br/>ë¡œê·¸ ì‹œê°í™”] --> D
    end
    
    style A fill:#e8f5e8
    style B fill:#e8f5e8
    style C fill:#e8f5e8
    style D fill:#4caf50
    style E fill:#fff3e0
    style F fill:#fff3e0
    style G fill:#fff3e0
    style H fill:#2196f3
    style I fill:#2196f3
    style J fill:#2196f3
```

**ê° ìš”ì†Œì˜ ì—­í• **:
- **ë©”íŠ¸ë¦­**: ì‹œìŠ¤í…œ ì„±ëŠ¥ ì§€í‘œ (CPU, ë©”ëª¨ë¦¬, ì‘ë‹µì‹œê°„)
- **ë¡œê·¸**: ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ë²¤íŠ¸ì™€ ì˜¤ë¥˜ ì •ë³´
- **ì¶”ì **: ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œì˜ ìš”ì²­ íë¦„ ì¶”ì 

### ğŸ” ê°œë… 2: ì»¨í…Œì´ë„ˆ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ (12ë¶„)
> **ì •ì˜**: ì»¨í…Œì´ë„ˆ í™˜ê²½ì— íŠ¹í™”ëœ ëª¨ë‹ˆí„°ë§ ë„êµ¬ë“¤ì˜ í†µí•© ìŠ¤íƒ

**CNCF ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ**:
```mermaid
graph TB
    subgraph "ë°ì´í„° ìˆ˜ì§‘ ê³„ì¸µ"
        A[cAdvisor<br/>ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­] --> D[Prometheus<br/>ë©”íŠ¸ë¦­ ì €ì¥ì†Œ]
        B[Node Exporter<br/>í˜¸ìŠ¤íŠ¸ ë©”íŠ¸ë¦­] --> D
        C[Application<br/>ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­] --> D
    end
    
    subgraph "ì €ì¥ ë° ì²˜ë¦¬"
        D --> E[AlertManager<br/>ì•Œë¦¼ ê´€ë¦¬]
        D --> F[Grafana<br/>ì‹œê°í™”]
    end
    
    subgraph "ë¡œê·¸ ìŠ¤íƒ"
        G[Fluent Bit<br/>ë¡œê·¸ ìˆ˜ì§‘] --> H[Elasticsearch<br/>ë¡œê·¸ ì €ì¥]
        H --> I[Kibana<br/>ë¡œê·¸ ë¶„ì„]
    end
    
    style A fill:#e8f5e8
    style B fill:#e8f5e8
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#4caf50
    style F fill:#4caf50
    style G fill:#f3e5f5
    style H fill:#f3e5f5
    style I fill:#f3e5f5
```

**ëª¨ë‹ˆí„°ë§ ì„¤ì • ì˜ˆì‹œ**:
```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']
  
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
  
  - job_name: 'app'
    static_configs:
      - targets: ['app:3000']
    metrics_path: '/metrics'
```

### ğŸ” ê°œë… 3: ì•Œë¦¼ê³¼ SLI/SLO (11ë¶„)
> **ì •ì˜**: ì„œë¹„ìŠ¤ ìˆ˜ì¤€ ì§€í‘œì™€ ëª©í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ íš¨ê³¼ì ì¸ ì•Œë¦¼ ì²´ê³„

**SLI/SLO í”„ë ˆì„ì›Œí¬**:
```mermaid
graph TB
    subgraph "ì„œë¹„ìŠ¤ ìˆ˜ì¤€ ê´€ë¦¬"
        A[SLI<br/>Service Level Indicator<br/>ì¸¡ì • ê°€ëŠ¥í•œ ì§€í‘œ] --> D[ì„œë¹„ìŠ¤ í’ˆì§ˆ ê´€ë¦¬]
        B[SLO<br/>Service Level Objective<br/>ëª©í‘œ ìˆ˜ì¤€] --> D
        C[SLA<br/>Service Level Agreement<br/>ê³„ì•½ ìˆ˜ì¤€] --> D
    end
    
    subgraph "ì•Œë¦¼ ì „ëµ"
        E[Error Budget<br/>ì˜¤ë¥˜ ì˜ˆì‚°] --> F[ì•Œë¦¼ ë°œìƒ]
        G[Burn Rate<br/>ì†Œì§„ ì†ë„] --> F
    end
    
    D --> E
    F --> H[ëŒ€ì‘ ì¡°ì¹˜]
    
    style A fill:#e8f5e8
    style B fill:#e8f5e8
    style C fill:#e8f5e8
    style D fill:#4caf50
    style E fill:#fff3e0
    style F fill:#ff9800
    style G fill:#fff3e0
    style H fill:#ff9800
```

**SLI/SLO ì˜ˆì‹œ**:
```yaml
# SLI ì •ì˜
availability_sli: |
  sum(rate(http_requests_total{status!~"5.."}[5m])) /
  sum(rate(http_requests_total[5m]))

latency_sli: |
  histogram_quantile(0.95, 
    sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
  )

# SLO ëª©í‘œ
slo_targets:
  availability: 99.9%  # 99.9% ê°€ìš©ì„±
  latency_p95: 200ms   # 95% ìš”ì²­ì´ 200ms ì´ë‚´
```

**ì•Œë¦¼ ê·œì¹™ ì˜ˆì‹œ**:
```yaml
# alerting.yml
groups:
- name: slo_alerts
  rules:
  - alert: HighErrorRate
    expr: |
      (
        sum(rate(http_requests_total{status=~"5.."}[5m])) /
        sum(rate(http_requests_total[5m]))
      ) > 0.01
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value | humanizePercentage }}"
```

**ê³ ê¸‰ ê´€ì¸¡ì„± ê¸°ë²•**:

**1. ì‚¬ìš©ì ì •ì˜ ë©”íŠ¸ë¦­**:
```javascript
// Node.js ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­
const client = require('prom-client');

// ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ì •ì˜
const orderCounter = new client.Counter({
  name: 'orders_total',
  help: 'Total number of orders',
  labelNames: ['status', 'product_category']
});

const orderDuration = new client.Histogram({
  name: 'order_processing_duration_seconds',
  help: 'Order processing duration',
  buckets: [0.1, 0.5, 1, 2, 5, 10]
});

const activeUsers = new client.Gauge({
  name: 'active_users_current',
  help: 'Current number of active users'
});

// ë©”íŠ¸ë¦­ ì‚¬ìš© ì˜ˆì‹œ
app.post('/order', async (req, res) => {
  const timer = orderDuration.startTimer();
  
  try {
    await processOrder(req.body);
    orderCounter.inc({ status: 'success', product_category: req.body.category });
    res.json({ success: true });
  } catch (error) {
    orderCounter.inc({ status: 'failed', product_category: req.body.category });
    res.status(500).json({ error: error.message });
  } finally {
    timer();
  }
});
```

**2. ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì„**:
```yaml
# fluentd ì„¤ì •
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<filter docker.**>
  @type parser
  key_name log
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

<match docker.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name docker-logs
  type_name _doc
  
  <buffer>
    @type file
    path /var/log/fluentd-buffers/docker.buffer
    flush_mode interval
    flush_interval 10s
  </buffer>
</match>
```

**3. ë¶„ì‚° ì¶”ì  (Distributed Tracing)**:
```javascript
// OpenTelemetry ì„¤ì •
const { NodeSDK } = require('@opentelemetry/sdk-node');
const { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');
const { JaegerExporter } = require('@opentelemetry/exporter-jaeger');

const jaegerExporter = new JaegerExporter({
  endpoint: 'http://jaeger:14268/api/traces',
});

const sdk = new NodeSDK({
  traceExporter: jaegerExporter,
  instrumentations: [getNodeAutoInstrumentations()]
});

sdk.start();

// ì‚¬ìš©ì ì •ì˜ ìŠ¤íŒ¬
const opentelemetry = require('@opentelemetry/api');

app.get('/api/user/:id', async (req, res) => {
  const tracer = opentelemetry.trace.getTracer('user-service');
  
  const span = tracer.startSpan('get-user-profile');
  span.setAttributes({
    'user.id': req.params.id,
    'http.method': req.method,
    'http.url': req.url
  });
  
  try {
    const user = await getUserProfile(req.params.id);
    span.setStatus({ code: opentelemetry.SpanStatusCode.OK });
    res.json(user);
  } catch (error) {
    span.recordException(error);
    span.setStatus({ 
      code: opentelemetry.SpanStatusCode.ERROR, 
      message: error.message 
    });
    res.status(500).json({ error: error.message });
  } finally {
    span.end();
  }
});
```

**4. ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ êµ¬ì„±**:
```json
{
  "dashboard": {
    "title": "Container Performance Dashboard",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ]
      },
      {
        "title": "Response Time P95",
        "type": "singlestat",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])"
          }
        ]
      },
      {
        "title": "Container Resource Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total[5m])",
            "legendFormat": "CPU - {{container_name}}"
          },
          {
            "expr": "container_memory_usage_bytes / 1024 / 1024",
            "legendFormat": "Memory MB - {{container_name}}"
          }
        ]
      }
    ]
  }
}
```

**5. ìë™ ì´ìƒ íƒì§€**:
```python
# ì´ìƒ íƒì§€ ìŠ¤í¬ë¦½íŠ¸
import numpy as np
from sklearn.ensemble import IsolationForest
import requests
import json
from datetime import datetime, timedelta

class AnomalyDetector:
    def __init__(self, prometheus_url):
        self.prometheus_url = prometheus_url
        self.model = IsolationForest(contamination=0.1)
        
    def fetch_metrics(self, query, hours=24):
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)
        
        params = {
            'query': query,
            'start': start_time.isoformat(),
            'end': end_time.isoformat(),
            'step': '5m'
        }
        
        response = requests.get(f"{self.prometheus_url}/api/v1/query_range", params=params)
        return response.json()
    
    def detect_anomalies(self):
        # CPU ì‚¬ìš©ë¥  ë°ì´í„° ìˆ˜ì§‘
        cpu_data = self.fetch_metrics('rate(container_cpu_usage_seconds_total[5m])')
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        values = []
        for result in cpu_data['data']['result']:
            for value in result['values']:
                values.append(float(value[1]))
        
        if len(values) < 10:
            return []
        
        # ì´ìƒ íƒì§€ ëª¨ë¸ í•™ìŠµ
        X = np.array(values).reshape(-1, 1)
        self.model.fit(X)
        
        # ì´ìƒì¹˜ íƒì§€
        anomalies = self.model.predict(X)
        anomaly_indices = np.where(anomalies == -1)[0]
        
        return [
            {
                'timestamp': datetime.now().isoformat(),
                'metric': 'cpu_usage',
                'value': values[i],
                'anomaly_score': self.model.decision_function(X[i].reshape(1, -1))[0]
            }
            for i in anomaly_indices
        ]

# ì‚¬ìš© ì˜ˆì‹œ
detector = AnomalyDetector('http://prometheus:9090')
anomalies = detector.detect_anomalies()

for anomaly in anomalies:
    print(f"Anomaly detected: {anomaly}")
    # Slack ë˜ëŠ” ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡
```

## ğŸ’­ í•¨ê»˜ ìƒê°í•´ë³´ê¸° (15ë¶„)

### ğŸ¤ í˜ì–´ í† ë¡  (10ë¶„)
**í† ë¡  ì£¼ì œ**:
1. **ê´€ì¸¡ì„± ìš°ì„ ìˆœìœ„**: "ë©”íŠ¸ë¦­, ë¡œê·¸, ì¶”ì  ì¤‘ ì–´ë–¤ ê²ƒë¶€í„° êµ¬ì¶•í•´ì•¼ í• ê¹Œìš”?"
2. **ì•Œë¦¼ í”¼ë¡œë„**: "ë„ˆë¬´ ë§ì€ ì•Œë¦¼ìœ¼ë¡œ ì¸í•œ í”¼ë¡œë„ë¥¼ ì–´ë–»ê²Œ ì¤„ì¼ê¹Œìš”?"
3. **SLO ì„¤ì •**: "ìš°ë¦¬ ì„œë¹„ìŠ¤ì— ì í•©í•œ SLOëŠ” ì–´ë–»ê²Œ ì„¤ì •í•´ì•¼ í• ê¹Œìš”?"

### ğŸ¯ ì „ì²´ ê³µìœ  (5ë¶„)
- **ëª¨ë‹ˆí„°ë§ ê²½í—˜**: íš¨ê³¼ì ì¸ ëª¨ë‹ˆí„°ë§ êµ¬ì¶• ê²½í—˜
- **ë„êµ¬ ì„ íƒ**: ì¡°ì§ ê·œëª¨ì— ë§ëŠ” ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„ íƒ ê¸°ì¤€

## ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ
- **Observability**: ê´€ì¸¡ì„±
- **SLI (Service Level Indicator)**: ì„œë¹„ìŠ¤ ìˆ˜ì¤€ ì§€í‘œ
- **SLO (Service Level Objective)**: ì„œë¹„ìŠ¤ ìˆ˜ì¤€ ëª©í‘œ
- **Error Budget**: ì˜¤ë¥˜ ì˜ˆì‚°
- **Alerting**: ì•Œë¦¼ ì‹œìŠ¤í…œ

## ğŸ“ ì„¸ì…˜ ë§ˆë¬´ë¦¬
### âœ… ì˜¤ëŠ˜ ì„¸ì…˜ ì„±ê³¼
- ê´€ì¸¡ì„± 3ìš”ì†Œ ì™„ì „ ì´í•´
- ì»¨í…Œì´ë„ˆ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ êµ¬ì„± ë°©ë²• í•™ìŠµ
- SLI/SLO ê¸°ë°˜ ì•Œë¦¼ ì²´ê³„ ì„¤ê³„ ëŠ¥ë ¥ ìŠµë“

### ğŸ¯ ë‹¤ìŒ ì„¸ì…˜ ì¤€ë¹„
- **ì‹¤ìŠµ ì±Œë¦°ì§€**: ë³´ì•ˆ & ìµœì í™” í†µí•© ì‹¤ìŠµ
- **ì—°ê²°**: ì´ë¡ ì—ì„œ ì‹¤ìŠµìœ¼ë¡œì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜

---

**ë‹¤ìŒ**: [ë³´ì•ˆ & ìµœì í™” í†µí•© ì‹¤ìŠµ](../README.md#ì‹¤ìŠµ-ì±Œë¦°ì§€)