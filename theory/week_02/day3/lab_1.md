# Week 2 Day 3 Lab 1: ìš´ì˜ê¸‰ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•

<div align="center">

**ğŸ“Š Prometheus + Grafana** â€¢ **ğŸ“ ELK Stack** â€¢ **ğŸ”” ì•Œë¦¼ ì‹œìŠ¤í…œ**

*í”„ë¡œë•ì…˜ í™˜ê²½ì„ ìœ„í•œ ì¢…í•© ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì‹œìŠ¤í…œ*

</div>

---

## ğŸ•˜ ì‹¤ìŠµ ì •ë³´

**ì‹œê°„**: 12:00-12:50 (50ë¶„)  
**ëª©í‘œ**: Prometheus + Grafana + ELK Stackì„ í™œìš©í•œ ì¢…í•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•  
**ë°©ì‹**: ë‹¨ê³„ë³„ êµ¬ì¶• + ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ + ì¥ì•  ì‹œë®¬ë ˆì´ì…˜

---

## ğŸ¯ ì‹¤ìŠµ ëª©í‘œ

### ğŸ“š ë‹¹ì¼ ì´ë¡  ì ìš©
- Session 1-3ì—ì„œ ë°°ìš´ ëª¨ë‹ˆí„°ë§, ë¡œê¹…, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ê°œë…ì„ í†µí•© êµ¬í˜„
- Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê³¼ Grafana ì‹œê°í™” ì‹¤ìŠµ
- ELK Stackì„ í†µí•œ ì¤‘ì•™í™”ëœ ë¡œê·¸ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•

### ğŸ—ï¸ êµ¬ì¶•í•  ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜
```mermaid
graph TB
    subgraph "ì• í”Œë¦¬ì¼€ì´ì…˜ ê³„ì¸µ"
        A[WordPress App<br/>ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­]
        B[MySQL DB<br/>ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­]
        C[Nginx Proxy<br/>ì›¹ì„œë²„ ë©”íŠ¸ë¦­]
    end
    
    subgraph "ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ê³„ì¸µ"
        D[cAdvisor<br/>ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­]
        E[Node Exporter<br/>ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­]
        F[MySQL Exporter<br/>DB ë©”íŠ¸ë¦­]
    end
    
    subgraph "ë¡œê·¸ ìˆ˜ì§‘ ê³„ì¸µ"
        G[Filebeat<br/>ë¡œê·¸ ìˆ˜ì§‘]
        H[Logstash<br/>ë¡œê·¸ ì²˜ë¦¬]
    end
    
    subgraph "ì €ì¥ ê³„ì¸µ"
        I[Prometheus<br/>ë©”íŠ¸ë¦­ ì €ì¥]
        J[Elasticsearch<br/>ë¡œê·¸ ì €ì¥]
    end
    
    subgraph "ì‹œê°í™” ê³„ì¸µ"
        K[Grafana<br/>ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ]
        L[Kibana<br/>ë¡œê·¸ ë¶„ì„]
    end
    
    subgraph "ì•Œë¦¼ ê³„ì¸µ"
        M[AlertManager<br/>ì•Œë¦¼ ê´€ë¦¬]
        N[Webhook<br/>Slack ì—°ë™]
    end
    
    A --> D
    B --> F
    C --> G
    D --> I
    E --> I
    F --> I
    G --> H
    H --> J
    I --> K
    I --> M
    J --> L
    M --> N
    
    style A fill:#e8f5e8
    style B fill:#e8f5e8
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fff3e0
    style F fill:#fff3e0
    style G fill:#fff3e0
    style H fill:#fff3e0
    style I fill:#f3e5f5
    style J fill:#f3e5f5
    style K fill:#ffebee
    style L fill:#ffebee
    style M fill:#e3f2fd
    style N fill:#e3f2fd
```

---

## ğŸ“‹ ì‹¤ìŠµ ì¤€ë¹„ (5ë¶„)

### í™˜ê²½ ì„¤ì •
```bash
# ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ~/monitoring-stack
cd ~/monitoring-stack

# ê¸°ì¡´ Day 2 WordPress ì‹œìŠ¤í…œ í™•ì¸
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ì¶”ê°€ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p {prometheus,grafana,elasticsearch,kibana,logstash,filebeat,alertmanager}
mkdir -p config/{prometheus,grafana,logstash,filebeat,alertmanager}
mkdir -p data/{prometheus,elasticsearch,grafana}
```

### í˜ì–´ êµ¬ì„±
- ğŸ‘¥ **ëª¨ë‹ˆí„°ë§ íŒ€**: 2ëª…ì”© ì§ì„ ì´ë£¨ì–´ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•
- ğŸ”„ **ì—­í•  ë¶„ë‹´**: ë©”íŠ¸ë¦­ ë‹´ë‹¹ / ë¡œê·¸ ë‹´ë‹¹ìœ¼ë¡œ ì—­í•  ë¶„ë‹´
- ğŸ“ **í†µí•© ì‘ì—…**: ìµœì¢…ì ìœ¼ë¡œ í†µí•© ëŒ€ì‹œë³´ë“œ êµ¬ì„±

---

## ğŸ”§ ì‹¤ìŠµ ë‹¨ê³„ (40ë¶„)

### Step 1: Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶• (15ë¶„)

**ğŸš€ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©**
```bash
# Prometheus ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ìë™ êµ¬ì¶•
./lab_scripts/lab1/setup_prometheus_stack.sh
```

**ğŸ“‹ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©**: [setup_prometheus_stack.sh](./lab_scripts/lab1/setup_prometheus_stack.sh)

**1-1. ìˆ˜ë™ ì‹¤í–‰ (í•™ìŠµìš©)**
```bash
# Prometheus ì„¤ì • íŒŒì¼ ìƒì„±
cat > config/prometheus/prometheus.yml << 'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # Prometheus ìì²´ ëª¨ë‹ˆí„°ë§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­ (cAdvisor)
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ (Node Exporter)
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # MySQL ë©”íŠ¸ë¦­
  - job_name: 'mysql-exporter'
    static_configs:
      - targets: ['mysql-exporter:9104']

  # Nginx ë©”íŠ¸ë¦­
  - job_name: 'nginx-exporter'
    static_configs:
      - targets: ['nginx-exporter:9113']
EOF

# ì•Œë¦¼ ê·œì¹™ ì„¤ì •
cat > config/prometheus/alert_rules.yml << 'EOF'
groups:
  - name: container_alerts
    rules:
      - alert: HighCPUUsage
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "Container {{ $labels.name }} CPU usage is above 80%"

      - alert: HighMemoryUsage
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 90
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High memory usage detected"
          description: "Container {{ $labels.name }} memory usage is above 90%"

      - alert: ContainerDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Container is down"
          description: "Container {{ $labels.instance }} has been down for more than 1 minute"
EOF

# Prometheus ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name prometheus \
  --restart=unless-stopped \
  -p 9090:9090 \
  -v $(pwd)/config/prometheus:/etc/prometheus \
  -v prometheus-data:/prometheus \
  --memory=1g \
  prom/prometheus:latest \
  --config.file=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path=/prometheus \
  --web.console.libraries=/etc/prometheus/console_libraries \
  --web.console.templates=/etc/prometheus/consoles \
  --storage.tsdb.retention.time=30d \
  --web.enable-lifecycle
```

**1-2. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ë°°í¬**
```bash
# cAdvisor (ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­)
docker run -d \
  --name cadvisor \
  --restart=unless-stopped \
  -p 8080:8080 \
  -v /:/rootfs:ro \
  -v /var/run:/var/run:ro \
  -v /sys:/sys:ro \
  -v /var/lib/docker/:/var/lib/docker:ro \
  -v /dev/disk/:/dev/disk:ro \
  --privileged \
  --device=/dev/kmsg \
  gcr.io/cadvisor/cadvisor:latest

# Node Exporter (ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­)
docker run -d \
  --name node-exporter \
  --restart=unless-stopped \
  -p 9100:9100 \
  -v /proc:/host/proc:ro \
  -v /sys:/host/sys:ro \
  -v /:/rootfs:ro \
  --pid=host \
  prom/node-exporter:latest \
  --path.procfs=/host/proc \
  --path.rootfs=/rootfs \
  --path.sysfs=/host/sys \
  --collector.filesystem.mount-points-exclude='^/(sys|proc|dev|host|etc)($$|/)'

# MySQL Exporter (ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­)
docker run -d \
  --name mysql-exporter \
  --restart=unless-stopped \
  -p 9104:9104 \
  -e DATA_SOURCE_NAME="wpuser:wppassword@(mysql-wordpress:3306)/" \
  --link mysql-wordpress:mysql-wordpress \
  prom/mysqld-exporter:latest
```

### Step 2: Grafana ëŒ€ì‹œë³´ë“œ êµ¬ì„± (10ë¶„)

**ğŸš€ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©**
```bash
# Grafana ëŒ€ì‹œë³´ë“œ ìë™ êµ¬ì„±
./lab_scripts/lab1/setup_grafana_dashboard.sh
```

**ğŸ“‹ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©**: [setup_grafana_dashboard.sh](./lab_scripts/lab1/setup_grafana_dashboard.sh)

**2-1. ìˆ˜ë™ ì‹¤í–‰ (í•™ìŠµìš©)**
```bash
# Grafana ì„¤ì • ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p config/grafana/{dashboards,datasources,provisioning}

# ë°ì´í„°ì†ŒìŠ¤ ì„¤ì •
cat > config/grafana/provisioning/datasources.yml << 'EOF'
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true

  - name: Elasticsearch
    type: elasticsearch
    access: proxy
    url: http://elasticsearch:9200
    database: "logs-*"
    interval: Daily
    timeField: "@timestamp"
    editable: true
EOF

# ëŒ€ì‹œë³´ë“œ í”„ë¡œë¹„ì €ë‹ ì„¤ì •
cat > config/grafana/provisioning/dashboards.yml << 'EOF'
apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /var/lib/grafana/dashboards
EOF

# Grafana ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \
  --name grafana \
  --restart=unless-stopped \
  -p 3000:3000 \
  -e GF_SECURITY_ADMIN_PASSWORD=admin \
  -e GF_USERS_ALLOW_SIGN_UP=false \
  -v grafana-data:/var/lib/grafana \
  -v $(pwd)/config/grafana/provisioning:/etc/grafana/provisioning \
  --link prometheus:prometheus \
  --memory=512m \
  grafana/grafana:latest
```

### Step 3: ELK Stack ë¡œê·¸ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• (10ë¶„)

**ğŸš€ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©**
```bash
# ELK Stack ìë™ êµ¬ì¶•
./lab_scripts/lab1/setup_elk_stack.sh
```

**ğŸ“‹ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©**: [setup_elk_stack.sh](./lab_scripts/lab1/setup_elk_stack.sh)

**3-1. ìˆ˜ë™ ì‹¤í–‰ (í•™ìŠµìš©)**
```bash
# Elasticsearch ì‹¤í–‰
docker run -d \
  --name elasticsearch \
  --restart=unless-stopped \
  -p 9200:9200 \
  -p 9300:9300 \
  -e "discovery.type=single-node" \
  -e "ES_JAVA_OPTS=-Xms512m -Xmx512m" \
  -e "xpack.security.enabled=false" \
  -v elasticsearch-data:/usr/share/elasticsearch/data \
  --memory=1g \
  elasticsearch:7.17.0

# Logstash ì„¤ì • íŒŒì¼ ìƒì„±
cat > config/logstash/logstash.conf << 'EOF'
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "nginx" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
  }
  
  if [fields][service] == "mysql" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{NUMBER:thread_id} \\[%{WORD:level}\\] %{GREEDYDATA:mysql_message}" }
    }
  }
  
  if [fields][service] == "wordpress" {
    if [message] =~ /^\[/ {
      grok {
        match => { "message" => "\\[%{HTTPDATE:timestamp}\\] %{WORD:level}: %{GREEDYDATA:php_message}" }
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
  }
  
  stdout {
    codec => rubydebug
  }
}
EOF

# Logstash ì‹¤í–‰
docker run -d \
  --name logstash \
  --restart=unless-stopped \
  -p 5044:5044 \
  -v $(pwd)/config/logstash:/usr/share/logstash/pipeline \
  --link elasticsearch:elasticsearch \
  --memory=1g \
  logstash:7.17.0

# Kibana ì‹¤í–‰
docker run -d \
  --name kibana \
  --restart=unless-stopped \
  -p 5601:5601 \
  -e ELASTICSEARCH_HOSTS=http://elasticsearch:9200 \
  --link elasticsearch:elasticsearch \
  --memory=512m \
  kibana:7.17.0
```

### Step 4: ì•Œë¦¼ ì‹œìŠ¤í…œ ë° í†µí•© í…ŒìŠ¤íŠ¸ (5ë¶„)

**ğŸš€ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©**
```bash
# ì•Œë¦¼ ì‹œìŠ¤í…œ ë° í†µí•© í…ŒìŠ¤íŠ¸
./lab_scripts/lab1/setup_alerting_test.sh
```

**ğŸ“‹ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©**: [setup_alerting_test.sh](./lab_scripts/lab1/setup_alerting_test.sh)

**4-1. ìˆ˜ë™ ì‹¤í–‰ (í•™ìŠµìš©)**
```bash
# AlertManager ì„¤ì •
cat > config/alertmanager/alertmanager.yml << 'EOF'
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@company.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://webhook:5000/alerts'
        send_resolved: true

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
EOF

# AlertManager ì‹¤í–‰
docker run -d \
  --name alertmanager \
  --restart=unless-stopped \
  -p 9093:9093 \
  -v $(pwd)/config/alertmanager:/etc/alertmanager \
  --link prometheus:prometheus \
  --memory=256m \
  prom/alertmanager:latest

# ê°„ë‹¨í•œ Webhook ì„œë²„ (ì•Œë¦¼ í…ŒìŠ¤íŠ¸ìš©)
cat > webhook-server.py << 'EOF'
from flask import Flask, request, jsonify
import json
from datetime import datetime

app = Flask(__name__)

@app.route('/alerts', methods=['POST'])
def receive_alert():
    alerts = request.json
    print(f"[{datetime.now()}] Received alerts:")
    print(json.dumps(alerts, indent=2))
    return jsonify({"status": "received"})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
EOF

# Webhook ì„œë²„ ì‹¤í–‰ (Python ì»¨í…Œì´ë„ˆ)
docker run -d \
  --name webhook \
  --restart=unless-stopped \
  -p 5000:5000 \
  -v $(pwd)/webhook-server.py:/app/webhook-server.py \
  -w /app \
  python:3.9-slim \
  sh -c "pip install flask && python webhook-server.py"
```

---

## âœ… ì‹¤ìŠµ ì²´í¬í¬ì¸íŠ¸

### ê¸°ë³¸ ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ
- [ ] **Prometheus**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥ ì •ìƒ ë™ì‘
- [ ] **Grafana**: ëŒ€ì‹œë³´ë“œ êµ¬ì„± ë° ì‹œê°í™” ì™„ë£Œ
- [ ] **Elasticsearch**: ë¡œê·¸ ì €ì¥ ë° ì¸ë±ì‹± ì •ìƒ ë™ì‘
- [ ] **Kibana**: ë¡œê·¸ ê²€ìƒ‰ ë° ë¶„ì„ ê°€ëŠ¥

### ì„¤ì • ë° êµ¬ì„± í™•ì¸
- [ ] **ë©”íŠ¸ë¦­ ìˆ˜ì§‘**: cAdvisor, Node Exporter, MySQL Exporter ì—°ë™
- [ ] **ë¡œê·¸ ìˆ˜ì§‘**: Filebeat â†’ Logstash â†’ Elasticsearch íŒŒì´í”„ë¼ì¸
- [ ] **ì•Œë¦¼ ì„¤ì •**: AlertManager ê·œì¹™ ì„¤ì • ë° Webhook ì—°ë™
- [ ] **ëŒ€ì‹œë³´ë“œ**: ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ê³¼ ë¡œê·¸ ì‹œê°í™”

### ë™ì‘ í…ŒìŠ¤íŠ¸ ì„±ê³µ

**ğŸš€ ìë™í™” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©**
```bash
# ì „ì²´ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸
./lab_scripts/lab1/test_monitoring_system.sh
```

**ğŸ“‹ ìŠ¤í¬ë¦½íŠ¸ ë‚´ìš©**: [test_monitoring_system.sh](./lab_scripts/lab1/test_monitoring_system.sh)

**ìˆ˜ë™ í…ŒìŠ¤íŠ¸ (í•µì‹¬ë§Œ)**
```bash
# 1. Prometheus ë©”íŠ¸ë¦­ í™•ì¸
curl http://localhost:9090/api/v1/targets

# 2. Grafana ì ‘ì† í™•ì¸
curl -I http://localhost:3000

# 3. Elasticsearch ìƒíƒœ í™•ì¸
curl http://localhost:9200/_cluster/health

# 4. ë¶€í•˜ í…ŒìŠ¤íŠ¸ (ì•Œë¦¼ íŠ¸ë¦¬ê±°)
docker run --rm -it \
  --link nginx-proxy:target \
  williamyeh/wrk \
  -t4 -c100 -d30s http://target/

# 5. ë¡œê·¸ ìƒì„± ë° í™•ì¸
docker logs nginx-proxy
curl "http://localhost:9200/logs-*/_search?q=*&size=10"
```

---

## ğŸ”„ ì‹¤ìŠµ ë§ˆë¬´ë¦¬ (5ë¶„)

### ê²°ê³¼ ê³µìœ 
- **ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ**: Grafanaì—ì„œ ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì‹œì—°
- **ë¡œê·¸ ë¶„ì„**: Kibanaì—ì„œ ë¡œê·¸ ê²€ìƒ‰ ë° íŒ¨í„´ ë¶„ì„
- **ì•Œë¦¼ í…ŒìŠ¤íŠ¸**: ì˜ë„ì  ë¶€í•˜ ë°œìƒìœ¼ë¡œ ì•Œë¦¼ ë™ì‘ í™•ì¸

### ì§ˆë¬¸ í•´ê²°
- **ë©”íŠ¸ë¦­ ì´í•´**: ê° ë©”íŠ¸ë¦­ì˜ ì˜ë¯¸ì™€ ì„ê³„ê°’ ì„¤ì • ë°©ë²•
- **ë¡œê·¸ íŒŒì‹±**: Logstash í•„í„° ì„¤ì •ê³¼ Grok íŒ¨í„´ ì´í•´
- **ëŒ€ì‹œë³´ë“œ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: Grafana íŒ¨ë„ ì„¤ì •ê³¼ ì¿¼ë¦¬ ì‘ì„±

### ë‹¤ìŒ ì—°ê²°
- **Lab 2 ì¤€ë¹„**: êµ¬ì¶•í•œ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ Swarm í´ëŸ¬ìŠ¤í„°ì— ì ìš©
- **í™•ì¥ ê³„íš**: ë©€í‹° ë…¸ë“œ í™˜ê²½ì—ì„œì˜ ëª¨ë‹ˆí„°ë§ ì „ëµ

---

## ğŸ¯ ì¶”ê°€ ë„ì „ ê³¼ì œ (ì‹œê°„ ì—¬ìœ ì‹œ)

### ê³ ê¸‰ ê¸°ëŠ¥ êµ¬í˜„
```bash
# 1. ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì¶”ê°€
cat > custom-exporter.py << 'EOF'
from prometheus_client import start_http_server, Gauge
import time
import psutil

# ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì •ì˜
cpu_temp = Gauge('system_cpu_temperature_celsius', 'CPU Temperature')
disk_usage = Gauge('system_disk_usage_percent', 'Disk Usage Percentage')

def collect_metrics():
    while True:
        # CPU ì˜¨ë„ (ì‹œë®¬ë ˆì´ì…˜)
        cpu_temp.set(psutil.cpu_percent())
        
        # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
        disk = psutil.disk_usage('/')
        disk_usage.set((disk.used / disk.total) * 100)
        
        time.sleep(15)

if __name__ == '__main__':
    start_http_server(8000)
    collect_metrics()
EOF

# 2. ë¡œê·¸ ê¸°ë°˜ ë©”íŠ¸ë¦­ ìƒì„±
# Logstashì—ì„œ ë©”íŠ¸ë¦­ ì¶”ì¶œí•˜ì—¬ Prometheusë¡œ ì „ì†¡

# 3. ê³ ê¸‰ ì•Œë¦¼ ê·œì¹™
# ë³µí•© ì¡°ê±´ê³¼ ì‹œê°„ ê¸°ë°˜ ì•Œë¦¼ ì„¤ì •
```

---

<div align="center">

**ğŸ“Š ìš´ì˜ê¸‰ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!**

**ë‹¤ìŒ**: [Lab 2 - Docker Swarm í´ëŸ¬ìŠ¤í„° êµ¬ì„±](./lab_2.md)

</div>